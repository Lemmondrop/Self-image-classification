{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2538f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPool2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4719607",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42678257",
   "metadata": {},
   "outputs": [],
   "source": [
    "pine_fir = \"./data/\"\n",
    "categories = [\"pitch_pine\",\"pine\",\"korean_pine\"]\n",
    "\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "pixels = image_w * image_h # 64 * 64의 이미지 크기를 가지고 RGB(3) 로 표현\n",
    "x = [] # Data 들어감\n",
    "y = [] # Labeling 들어감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = np.load(\"./5obj_1.npy\", allow_pickle=True)\n",
    "\n",
    "X_train = X_train.astype(\"float\") / 256\n",
    "X_test = X_test.astype(\"float\") / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa112f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c0c68",
   "metadata": {},
   "source": [
    "# create CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() ## this model is very general\n",
    "## When using this CNN, modify the internals to make it work for you\n",
    "\n",
    "model.add(Convolution2D(64, (3,3), padding='same', input_shape = X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(128, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, (3,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.run_eagerly = True\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59b63f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e514ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [write you want batch size]\n",
    "epochs = [write you want epochs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8fe25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c1db5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.title('acc')\n",
    "plt.plot(history.history['acc'], 'b', label='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.title('loss')\n",
    "plt.plot(history.history['loss'], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5569124",
   "metadata": {},
   "source": [

   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4194d40",
   "metadata": {},
   "source": [
    "# Channel visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './For example, enter the address of the image you want to print'\n",
    "from keras.preprocessing import image\n",
    "\n",
    "img = tf.keras.utils.load_img(img_path, target_size=(64, 64))\n",
    "img_tensor = tf.keras.utils.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor , axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391421bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f72f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "activation_model = models.Model(inputs = model.input, outputs = layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193bc0bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "activations = activation_model.predict(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ffceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e101d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(first_layer_activation[0, :, :, 62], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e29ca8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(first_layer_activation[0, :, :, 10], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * 16 + col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94197c26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the name of the layer as the graph title\n",
    "layer_names = []\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "# Draw an feature map\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    # Number of features in the feature map\n",
    "    n_features = layer_activation.shape[-1]\n",
    "\n",
    "    # feature map size (1, size, size, n_features)\n",
    "    size = layer_activation.shape[1]\n",
    "\n",
    "    # Find the grid size for the activation channel\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    # Fill each activation into one large grid\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             col * images_per_row + row]\n",
    "            # Process attributes for graphical representation\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size,\n",
    "                         row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "    # print greed\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0230826",
   "metadata": {},
   "source": [
    "# CNN filter visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48656ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38139ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'conv2d_2'\n",
    "filter_index = 0\n",
    "\n",
    "layer_output = model.get_layer(layer_name).output\n",
    "loss = K.mean(layer_output[:,:,:, filter_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e775a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first tensor from the tensor list returned by the gradients function\n",
    "grads = K.gradients(loss, model.input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e183370",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads /= (K.sqrt(K.mean(K.square(grads))) * 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485dcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate = K.function([model.input], [loss, grads])\n",
    "\n",
    "loss_value, grads_value = iterate([np.zeros((1, 64, 64, 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128.\n",
    "\n",
    "# The size of the gradient to update\n",
    "step = 1.\n",
    "for i in range(40):   # Run the gradient ascent method 40 times\n",
    "    # Calculate loss and gradient\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    # Modify the input image in a way that maximizes loss\n",
    "    input_img_data += grads_value * step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63091b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # Normalize the tensor to have a mean of 0 and a standard deviation of 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # Clipping to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # Convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd7f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "    # Define a loss function to maximize activation for a given layer and filter\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # Calculate the gradient of an input image for a loss\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "\n",
    "    # Gradient Normalization\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # Returns the loss and gradient for an input image\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "    \n",
    "    # Start with a noisy gray image\n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "\n",
    "    # Run 40 steps of the gradient ascent method\n",
    "    step = 1.\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad88cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generate_pattern('conv2d_2', 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b99a9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for layer_name in ['conv2d', 'conv2d_1', 'conv2d_2']:\n",
    "    size = 64\n",
    "    margin = 5\n",
    "\n",
    "    # An empty (black) image to hold the result\n",
    "    results = np.zeros((8 * size + 7 * margin, 8 * size + 7 * margin, 3), dtype='uint8')\n",
    "\n",
    "    for i in range(8):  # Iterate over the rows in the results grid\n",
    "        for j in range(8):  # Iterate over the columns in the results grid\n",
    "            # Generate a pattern for the i + (j * 8)th filter in layer_name\n",
    "            filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\n",
    "\n",
    "            # Save at position (i, j) in the results grid\n",
    "            horizontal_start = i * size + i * margin\n",
    "            horizontal_end = horizontal_start + size\n",
    "            vertical_start = j * size + j * margin\n",
    "            vertical_end = vertical_start + size\n",
    "            results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img\n",
    "\n",
    "    # Draw the results grid\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(results)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f2f19",
   "metadata": {},
   "source": [
    "# glad-CAM(Class Activation Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbca8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_img_path = './data/korean_pine/13.jpg'\n",
    "\n",
    "cam_img = tf.keras.utils.load_img(cam_img_path, target_size=(224, 224)) # Returns as a PIL object of size 224 x 224\n",
    "x = tf.keras.utils.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adecf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_pine_output = model.output[: , 1]\n",
    "last_conv_layer = model.get_layer('conv2d_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = K.gradients(korean_pine_output, last_conv_layer.output)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa676ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads = K.mean(grads, axis=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate = K.function([model.input],\n",
    "                        [pooled_grads, last_conv_layer.output[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e54a21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pooled_grads_value, conv_layer_output_value = iterate([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ff657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_CLASS):\n",
    "    conv_layer_output_value[:,:,i] *= pooled_grads_value[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
    "gradCAM = np.maximum(heatmap, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradCAM /= np.max(gradCAM)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db61b01c",
   "metadata": {},
   "source": [
    "# Overlaying a CAM Source Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e865045",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bf146",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_img = cv2.imread(cam_img_path)\n",
    "heatmap = cv2.resize( heatmap, (224, 224))\n",
    "heatmap = np.uint8( 255 * heatmap )\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = heatmap * 0.4 + cam_img\n",
    "\n",
    "cv2.imwrite('./The address of the image you want to return', superimposed_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd30bc",
   "metadata": {},
   "source": [
    "# Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c1f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
